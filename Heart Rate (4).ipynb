{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Data: https://archive.ics.uci.edu/ml/datasets/WESAD+%28Wearable+Stress+and+Affect+Detection%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Rate\n",
    "This program is how I aquired the heart rate data and windows to be used in machine learning analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hrv.rri import RRi\n",
    "from hrv.io import read_from_csv\n",
    "import neurokit as nk\n",
    "from hrv.classical import time_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Heart Rate Variance / Heart Rate\n",
    "This function is used in the main findrrv function where it recieved a dictionary of a describe method (the method that is used to describe a dataframe called describe()) and returns a dictionary with just the important stuff (mean, median, standard deviation, and variance) for both HRV and HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hrv(hrv):\n",
    "    returnhrDic = {}\n",
    "    returnhrvDic = {}\n",
    "    \n",
    "    returnhrDic['meanHr'] = hrv['mean']['hr']\n",
    "    returnhrDic['medianHr'] = hrv['median']['hr']\n",
    "    returnhrDic['stdHr'] = hrv['std']['hr']\n",
    "    returnhrDic['varHr'] = hrv['var']['hr']\n",
    "    \n",
    "    \n",
    "    returnhrvDic['meanHrv'] = hrv['mean']['rri']\n",
    "    returnhrvDic['medianHrv'] = hrv['median']['rri']\n",
    "    returnhrvDic['stdHrv'] = hrv['std']['rri']\n",
    "    returnhrvDic['varHrv'] = hrv['var']['rri']\n",
    "    \n",
    "    return returnhrDic,returnhrvDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Respiratory Rate Variability (heart rate)\n",
    "this is the main function in this program, where I use a module called nk to retieve where the peaks of the heart rate are. Then, I use this and some math to find the intervals of these peaks and call ir hrv (heart rate variability or respiratory rate variability) I use this to find heart rate, and to gather some other useful attubitues from the time_domain function which is from the nk module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findrrv(p):\n",
    "    samplingRate = 700\n",
    "    shiftStep = 175\n",
    "    returnDf = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i in range(0,len(p),shiftStep):\n",
    "        try:\n",
    "            bio = nk.ecg_preprocess(ecg=p[i:i+(samplingRate*60)][0], sampling_rate=samplingRate)\n",
    "            #hrv = nk.bio_ecg.ecg_hrv(rpeaks=bio['ECG']['R_Peaks'], sampling_rate=sampling_rate)\n",
    "            #print(bio['ECG']['R_Peaks'])\n",
    "            #peakTimes = list(scipy.signal.find_peaks(p[i:i+(samplingRate*60)]['y'],100,distance = 25))[0]\n",
    "            #print(peakTimes)\n",
    "            peakTimes = bio['ECG']['R_Peaks']\n",
    "            peakTimes = np.diff(peakTimes)\n",
    "            peakTimes = peakTimes/samplingRate\n",
    "            peakTimes = peakTimes.astype(float)\n",
    "            hrv = RRi(peakTimes)\n",
    "            hrdic,hrvdic = get_hrv(hrv.describe())\n",
    "            time = time_domain(hrv)\n",
    "            returnDic = dict(hrdic,**hrvdic)\n",
    "            returnDic.update(time)\n",
    "            temp = pd.DataFrame(returnDic,index=[i])\n",
    "            returnDf = returnDf.append(temp,ignore_index=True)\n",
    "            #hrv = nk.bio_ecg.ecg_hrv(rri=peakTimes, sampling_rate=sampling_rate,hrv_features=['time'])   \n",
    "            count += 1\n",
    "        except Exception as inst:\n",
    "            print(p[i:i+(samplingRate*60)][0])\n",
    "            print(inst)\n",
    "    #print(count)\n",
    "    return returnDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respirtory Data\n",
    "Here is the code that we used to gather the respirtory data as well as the temp and EMG data. It's very similar to the Heart rate gathering technic but doesn't have a fancy module do find the right peaks. For Respirtory data we just used scipy.signal's find_peaks to find the peaks of the data and say that at each peak is one breath. otherwise, it's basically the same as get data and heart rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, freqz, find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "def getData(sID):\n",
    "    fileStr = \"WESAD/WESAD/S{}/S{}.pkl\".format(sID,sID)\n",
    "    file = open(fileStr,'rb')\n",
    "    p = pickle._Unpickler(file)\n",
    "    p.encoding = 'latin1'\n",
    "    u = p.load()\n",
    "    data = u['signal']['chest']['Resp']\n",
    "    labels = u['label']\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "    df['label'] = pd.Series(labels, index=df.index)\n",
    "    y = butter_lowpass_filter(data, cutoff, fs, order) # Filter data\n",
    "    #y = data                                            # Don't filter data\n",
    "    df['y'] = pd.DataFrame(y)\n",
    "    stressDF = df[(df['label'] == 2)]\n",
    "\n",
    "    return stressDF[\"y\"].values\n",
    "\n",
    "def plotData(y):\n",
    "    T = 6079.0         # seconds\n",
    "    n = int(T * fs) # total number of samples\n",
    "    t = np.linspace(0, T, n, endpoint=False)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(2, 1, 2)\n",
    "    #plt.plot(t, data, 'b-', label='data')\n",
    "    plt.plot(range(len(y)), y, 'g-', linewidth=2, label='filtered data')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylim()\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    plt.show()\n",
    "\n",
    "# Filter requirements.\n",
    "order = 6\n",
    "fs = 700.0      # sample rate, Hz\n",
    "cutoff = 5  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "# Create new data columns from the previous data\n",
    "# Mean, Standard Deviation, Max, Min, Range, Slope\n",
    "# id, subjID, time, Mean, Standard Deviation, Max, Min, range, slope\n",
    "# 1, 2, 60, ...\n",
    "# 2, 2, 120, ...\n",
    "# 3, 2, 180, ...\n",
    "\n",
    "timeFrame = 60 # 60 Seconds\n",
    "timeShift = 0.25 # Shift the timeFrame up by 0.25 seconds\n",
    "\n",
    "subjectIDs = [2]#,3,4,5,6,7,8,9,10,11,13,14,15,16,17]\n",
    "\n",
    "\n",
    "# Iterate through all the subject data\n",
    "for sID in subjectIDs:\n",
    "    indID = 1\n",
    "    outFile = open(\"WESAD/WESAD/S{}/S{}Respstress.csv\".format(sID,sID), \"w\")\n",
    "    outFile.write(\",mean,standard_deviation,max,min,range,slope,breath_rate,in_ex_ratio,in_mean,in_std,ex_mean,ex_std,\\n\")\n",
    "\n",
    "    data = getData(sID)\n",
    "    #plotData(data)\n",
    "    print(sID, data)\n",
    "\n",
    "    start_t = 0\n",
    "    end_t = int(fs*timeFrame)\n",
    "    step = int(fs*timeShift)\n",
    "    while end_t <= data.size:\n",
    "        time_seg = data[start_t:end_t]\n",
    "\n",
    "        sMean = time_seg.mean()\n",
    "        sStd = np.std(time_seg)\n",
    "        sMin = time_seg.min()\n",
    "        sMax = time_seg.max()\n",
    "        sRange = sMax - sMin\n",
    "        sSlope = (time_seg[-1] - time_seg[0]) / (end_t - start_t)\n",
    "        # HERE IS THE CHANGE\n",
    "        iPeaks = find_peaks(time_seg,distance=1000,height=1)\n",
    "        iPeakHeights = iPeaks[-1][\"peak_heights\"]\n",
    "        #print(len(time_seg), time_seg)\n",
    "        print(len(iPeaks[0]),iPeaks)\n",
    "\n",
    "        pRate = len(iPeaks[0]) / timeFrame\n",
    "        pMean_In = iPeakHeights.mean()\n",
    "        pStd_In = np.std(iPeakHeights)\n",
    "        num_In = len(iPeakHeights)\n",
    "        # Invert the data (look at exhales)\n",
    "        \n",
    "        for pos in range(len(time_seg)):\n",
    "            time_seg[pos] = time_seg[pos] * -1\n",
    "        ePeaks = find_peaks(time_seg, distance=1000, height=1)\n",
    "        ePeakHeights = ePeaks[-1][\"peak_heights\"]\n",
    "        pStd_Ex = np.std(ePeakHeights)\n",
    "        pMean_Ex = ePeakHeights.mean()\n",
    "        num_Ex = len(ePeakHeights)\n",
    "        # TO ABOUT HERE IS WHERE THINGS ARE DIFFERENT\n",
    "        pRatio = num_In / num_Ex\n",
    "\n",
    "        outFile.write(\"{},{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(indID,sMean,sStd,sMax,sMin,sRange,sSlope,pRate,pRatio,pMean_In,pStd_In,pMean_Ex,pStd_Ex))\n",
    "\n",
    "        start_t += step\n",
    "        end_t += step\n",
    "        indID += 1\n",
    "\n",
    "    #plotData(data)\n",
    "    outFile.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
