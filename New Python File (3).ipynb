{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Data: https://archive.ics.uci.edu/ml/datasets/WESAD+%28Wearable+Stress+and+Affect+Detection%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "In this program, I follow the basic steps to completing a machine learning project on the WESAD data to determine if it is possible to notice a difference between someone who is very stress, or very amused. I use sklearn to accomplish the machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intial Preperation\n",
    "Before I can split the data into train and test sets, I needed to read in the data and remove some of the not as important lines (NaN data) and columns (start times, unnamed columns, subject etc.) Once the data only had interesting columns and rows, we looked at a describtion of the data and noticed some variablity in the differences in means. So after we split the data into train and test sets, we preformed a standarized scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('alldata.csv')\n",
    "df.dropna(how='all',inplace=True)\n",
    "dfmeans = df.mean(axis=0)\n",
    "df.replace(np.nan,dfmeans,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanHrECG</th>\n",
       "      <th>medianHrECG</th>\n",
       "      <th>stdHrECG</th>\n",
       "      <th>varHrECG</th>\n",
       "      <th>meanHrvECG</th>\n",
       "      <th>medianHrvECG</th>\n",
       "      <th>stdHrvECG</th>\n",
       "      <th>varHrvECG</th>\n",
       "      <th>rmssdECG</th>\n",
       "      <th>sdnnECG</th>\n",
       "      <th>...</th>\n",
       "      <th>maxEMG</th>\n",
       "      <th>minEMG</th>\n",
       "      <th>rangeEMG</th>\n",
       "      <th>slopeEMG</th>\n",
       "      <th>meanEMG.1</th>\n",
       "      <th>standard_deviationEMG.1</th>\n",
       "      <th>maxEMG.1</th>\n",
       "      <th>minEMG.1</th>\n",
       "      <th>rangeEMG.1</th>\n",
       "      <th>slopeEMG.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>6.196700e+04</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>61967.000000</td>\n",
       "      <td>6.196700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.026910</td>\n",
       "      <td>89.140086</td>\n",
       "      <td>7.770233</td>\n",
       "      <td>72.198734</td>\n",
       "      <td>715.590683</td>\n",
       "      <td>709.937213</td>\n",
       "      <td>68.066695</td>\n",
       "      <td>5850.622679</td>\n",
       "      <td>50.795323</td>\n",
       "      <td>68.725053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078712</td>\n",
       "      <td>-0.093777</td>\n",
       "      <td>0.172488</td>\n",
       "      <td>-3.217047e-09</td>\n",
       "      <td>-0.002932</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.126293</td>\n",
       "      <td>-0.132217</td>\n",
       "      <td>0.258509</td>\n",
       "      <td>1.200035e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.491811</td>\n",
       "      <td>21.164442</td>\n",
       "      <td>3.438373</td>\n",
       "      <td>76.888981</td>\n",
       "      <td>157.587127</td>\n",
       "      <td>161.326563</td>\n",
       "      <td>34.893657</td>\n",
       "      <td>6037.382592</td>\n",
       "      <td>44.263938</td>\n",
       "      <td>35.117294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050872</td>\n",
       "      <td>0.055850</td>\n",
       "      <td>0.104647</td>\n",
       "      <td>2.739441e-07</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.115837</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>0.240302</td>\n",
       "      <td>5.878626e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>46.296813</td>\n",
       "      <td>46.296813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>402.749511</td>\n",
       "      <td>398.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.010153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>-0.338058</td>\n",
       "      <td>0.066605</td>\n",
       "      <td>-6.280000e-06</td>\n",
       "      <td>-0.006313</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.065598</td>\n",
       "      <td>-3.600000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.712579</td>\n",
       "      <td>75.134409</td>\n",
       "      <td>5.434085</td>\n",
       "      <td>29.529280</td>\n",
       "      <td>602.681314</td>\n",
       "      <td>594.285714</td>\n",
       "      <td>44.265014</td>\n",
       "      <td>1959.391507</td>\n",
       "      <td>19.611366</td>\n",
       "      <td>44.705586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>-0.097154</td>\n",
       "      <td>0.100388</td>\n",
       "      <td>-6.650000e-08</td>\n",
       "      <td>-0.003594</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.061393</td>\n",
       "      <td>-0.144882</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>-2.440000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84.265266</td>\n",
       "      <td>84.337349</td>\n",
       "      <td>7.087726</td>\n",
       "      <td>50.235863</td>\n",
       "      <td>718.710801</td>\n",
       "      <td>711.428571</td>\n",
       "      <td>62.911656</td>\n",
       "      <td>3957.876464</td>\n",
       "      <td>38.881723</td>\n",
       "      <td>63.448132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061393</td>\n",
       "      <td>-0.074158</td>\n",
       "      <td>0.132169</td>\n",
       "      <td>-1.470000e-09</td>\n",
       "      <td>-0.003082</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>0.089584</td>\n",
       "      <td>-0.101486</td>\n",
       "      <td>0.198532</td>\n",
       "      <td>-1.470000e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.403899</td>\n",
       "      <td>100.961539</td>\n",
       "      <td>9.269878</td>\n",
       "      <td>85.930645</td>\n",
       "      <td>801.819961</td>\n",
       "      <td>798.571429</td>\n",
       "      <td>85.403348</td>\n",
       "      <td>7293.731832</td>\n",
       "      <td>63.415978</td>\n",
       "      <td>86.202438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100296</td>\n",
       "      <td>-0.057907</td>\n",
       "      <td>0.201004</td>\n",
       "      <td>6.100000e-08</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>0.155273</td>\n",
       "      <td>-0.070475</td>\n",
       "      <td>0.294754</td>\n",
       "      <td>2.470000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>149.121673</td>\n",
       "      <td>150.537634</td>\n",
       "      <td>30.646925</td>\n",
       "      <td>939.233994</td>\n",
       "      <td>1297.857143</td>\n",
       "      <td>1297.857143</td>\n",
       "      <td>343.922180</td>\n",
       "      <td>118282.465600</td>\n",
       "      <td>551.840150</td>\n",
       "      <td>371.478411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265915</td>\n",
       "      <td>-0.040192</td>\n",
       "      <td>0.574951</td>\n",
       "      <td>4.600000e-06</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.082655</td>\n",
       "      <td>1.047180</td>\n",
       "      <td>-0.040970</td>\n",
       "      <td>2.547180</td>\n",
       "      <td>3.520000e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanHrECG   medianHrECG      stdHrECG      varHrECG    meanHrvECG  \\\n",
       "count  61967.000000  61967.000000  61967.000000  61967.000000  61967.000000   \n",
       "mean      89.026910     89.140086      7.770233     72.198734    715.590683   \n",
       "std       20.491811     21.164442      3.438373     76.888981    157.587127   \n",
       "min       46.296813     46.296813      0.000000      0.000000    402.749511   \n",
       "25%       75.712579     75.134409      5.434085     29.529280    602.681314   \n",
       "50%       84.265266     84.337349      7.087726     50.235863    718.710801   \n",
       "75%      100.403899    100.961539      9.269878     85.930645    801.819961   \n",
       "max      149.121673    150.537634     30.646925    939.233994   1297.857143   \n",
       "\n",
       "       medianHrvECG     stdHrvECG      varHrvECG      rmssdECG       sdnnECG  \\\n",
       "count  61967.000000  61967.000000   61967.000000  61967.000000  61967.000000   \n",
       "mean     709.937213     68.066695    5850.622679     50.795323     68.725053   \n",
       "std      161.326563     34.893657    6037.382592     44.263938     35.117294   \n",
       "min      398.571429      0.000000       0.000000      1.428571      1.010153   \n",
       "25%      594.285714     44.265014    1959.391507     19.611366     44.705586   \n",
       "50%      711.428571     62.911656    3957.876464     38.881723     63.448132   \n",
       "75%      798.571429     85.403348    7293.731832     63.415978     86.202438   \n",
       "max     1297.857143    343.922180  118282.465600    551.840150    371.478411   \n",
       "\n",
       "       ...        maxEMG        minEMG      rangeEMG      slopeEMG  \\\n",
       "count  ...  61967.000000  61967.000000  61967.000000  6.196700e+04   \n",
       "mean   ...      0.078712     -0.093777      0.172488 -3.217047e-09   \n",
       "std    ...      0.050872      0.055850      0.104647  2.739441e-07   \n",
       "min    ...      0.022659     -0.338058      0.066605 -6.280000e-06   \n",
       "25%    ...      0.043613     -0.097154      0.100388 -6.650000e-08   \n",
       "50%    ...      0.061393     -0.074158      0.132169 -1.470000e-09   \n",
       "75%    ...      0.100296     -0.057907      0.201004  6.100000e-08   \n",
       "max    ...      0.265915     -0.040192      0.574951  4.600000e-06   \n",
       "\n",
       "          meanEMG.1  standard_deviationEMG.1      maxEMG.1      minEMG.1  \\\n",
       "count  61967.000000             61967.000000  61967.000000  61967.000000   \n",
       "mean      -0.002932                 0.014236      0.126293     -0.132217   \n",
       "std        0.001412                 0.007998      0.115837      0.144272   \n",
       "min       -0.006313                 0.007209      0.023758     -1.500000   \n",
       "25%       -0.003594                 0.010228      0.061393     -0.144882   \n",
       "50%       -0.003082                 0.012178      0.089584     -0.101486   \n",
       "75%       -0.002668                 0.015758      0.155273     -0.070475   \n",
       "max        0.002455                 0.082655      1.047180     -0.040970   \n",
       "\n",
       "         rangeEMG.1    slopeEMG.1  \n",
       "count  61967.000000  6.196700e+04  \n",
       "mean       0.258509  1.200035e-09  \n",
       "std        0.240302  5.878626e-07  \n",
       "min        0.065598 -3.600000e-05  \n",
       "25%        0.133118 -2.440000e-07  \n",
       "50%        0.198532 -1.470000e-09  \n",
       "75%        0.294754  2.470000e-07  \n",
       "max        2.547180  3.520000e-05  \n",
       "\n",
       "[8 rows x 69 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['endEDA','startEDA','amuse',\n",
    "              'labelEDA','labelEDAwrist','endEDAwrist',\n",
    "              'startEDAwrist','labelEDA','labelEDAwrist','Unnamed: 0','subject'],axis=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meanHrECG', 'medianHrECG', 'stdHrECG', 'varHrECG', 'meanHrvECG',\n",
       "       'medianHrvECG', 'stdHrvECG', 'varHrvECG', 'rmssdECG', 'sdnnECG',\n",
       "       'nn50ECG', 'pnn50ECG', 'mrriECG', 'mhrECG', 'meanEDA', 'stdEDA',\n",
       "       'rangeEDA', 'maxEDA', 'minEDA', 'slopeEDA', 'meanEDAwrist',\n",
       "       'stdEDAwrist', 'rangeEDAwrist', 'maxEDAwrist', 'minEDAwrist',\n",
       "       'slopeEDAwrist', 'stress', 'meanResp', 'standard_deviationResp',\n",
       "       'maxResp', 'minResp', 'rangeResp', 'slopeResp', 'breath_rateResp',\n",
       "       'in_ex_ratioResp', 'in_meanResp', 'in_stdResp', 'ex_meanResp',\n",
       "       'ex_stdResp', 'meanResp.1', 'standard_deviationResp.1', 'maxResp.1',\n",
       "       'minResp.1', 'rangeResp.1', 'slopeResp.1', 'breath_rateResp.1',\n",
       "       'in_ex_ratioResp.1', 'in_meanResp.1', 'in_stdResp.1', 'ex_meanResp.1',\n",
       "       'ex_stdResp.1', 'meanTemp', 'standard_deviationTemp', 'maxTemp',\n",
       "       'minTemp', 'rangeTemp', 'slopeTemp', 'meanEMG', 'standard_deviationEMG',\n",
       "       'maxEMG', 'minEMG', 'rangeEMG', 'slopeEMG', 'meanEMG.1',\n",
       "       'standard_deviationEMG.1', 'maxEMG.1', 'minEMG.1', 'rangeEMG.1',\n",
       "       'slopeEMG.1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['stress'],axis=1)\n",
    "Y=df['stress']\n",
    "X, XTest, Y, YTest = train_test_split(X,Y, train_size = 0.8,random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler\n",
    "In these three lines of code, I transform the training set parameters into a normalized standard data. What this means is that all data are changed into where they would be if the data was in a normal distrubition graph (with 1 being 1 standard deviation away from the mean, 2 being 2 std away and so on). I also do this for the test set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = StandardScaler()\n",
    "xStand = standard.fit_transform(X)\n",
    "xTestStand = standard.transform(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demention Reduction\n",
    "With so many different features that we extracted from the raw data, we needed to find the few that where really nessesary to better generalize to the final test set. This will allow new data (potenital not from this study however we didn't look into that) to have a better chance of correctly being identified. Mainly just not overfitting the data. We used PCA to find where the correct number of attubites would be and found that 28 attubiutes correctly explained about 95% of the variation in the data so we went with keeping those 28. The 28 attubites' explained variation is also given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(xStand)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "print(d)\n",
    "plt.plot(cumsum)\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.axhline(y=1, color='black', linestyle='--')\n",
    "plt.axvline(x=d,color='r',linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17305864, 0.11419787, 0.07572288, 0.06511276, 0.05517322,\n",
       "       0.05014901, 0.04750093, 0.04471977, 0.04019645, 0.02763329,\n",
       "       0.02512391, 0.02148717, 0.01965797, 0.01749623, 0.016579  ,\n",
       "       0.01522622, 0.01496167, 0.0147875 , 0.01447514, 0.01426878,\n",
       "       0.01417511, 0.01337925, 0.01243999, 0.01200354, 0.00960948,\n",
       "       0.00872842, 0.00785272, 0.00694008])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=d)\n",
    "XDim = pca.fit_transform(xStand)\n",
    "XTestDim = pca.transform(xTestStand)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preforming Machine Learning\n",
    "Here we selected 6 different algorithums. These algorithums are suitible for this project because we are trying to classifier if a time frame is during a stress point or an amused point. And all 6 of these algorithums are normally used in classification. In the end, we choose Random Forest Classifier because of it's low root mean square error compared to the others. \n",
    "We also ran the f-score, perision, and recall predictions on each model and Random Forest classifier still performed the best with a very high .999 or higher on all three. Along with an accuracy of also .999 \n",
    "Finally, we made a confusion matrix of the training set's Random Forest Classifier and found that it only missed 29 times out of the 49,573 total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "sgd = SGDClassifier()\n",
    "svc = LinearSVC()\n",
    "knc = KNeighborsClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "vote = VotingClassifier([('lr', lr), ('rf', rfc), ('svc', svc),('knc',knc),('sgd',sgd)],voting='hard')\n",
    "#listOfModels = [lr,sgd,svc,knc,rfc,vote]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.2664490732891017 std: 0.0056103767798242185\n",
      "mean: 0.30497104792018404 std: 0.005212464388369008\n",
      "mean: 0.26602436740065155 std: 0.0059756549509440956\n",
      "mean: 0.06841179452671804 std: 0.007766091400544526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.017473524780848713 std: 0.008829730606143234\n",
      "mean: 0.23730011437080784 std: 0.008368155387873246\n"
     ]
    }
   ],
   "source": [
    "def testModel(model,X,Y):\n",
    "    model.fit(X,Y)\n",
    "    scores = cross_val_score(model,X, Y,scoring='neg_mean_squared_error',cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    print (\"mean: %s std: %s\" % (rmse_scores.mean(),rmse_scores.std()))\n",
    "for i in listOfModels:\n",
    "    testModel(i,XDim,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) Persision: 0.9997174520453332 Recall: 0.9994036970781157 f-score: 0.9995605499403605\n"
     ]
    }
   ],
   "source": [
    "def testModel(model,X,Y):\n",
    "    model.fit(X,Y)\n",
    "    yPred = cross_val_predict(model, X, Y,cv=10)\n",
    "    print('ngram: %s Persision: %s Recall: %s f-score: %s' %(model, precision_score(Y,yPred),recall_score(Y,yPred),f1_score(Y,yPred)))\n",
    "for i in listOfModels:\n",
    "    testModel(i,XDim,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_scores mean is 0.01874077365060986 and sd is 0.01316335259005014\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(XDim,Y)\n",
    "scores = cross_val_score(rfc,XDim,Y,scoring='neg_mean_squared_error',cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print('rmse_scores mean is %s and sd is %s'%(rmse_scores.mean(),rmse_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995562100336877\n",
      "[[17706     4]\n",
      " [   18 31845]]\n"
     ]
    }
   ],
   "source": [
    "YPred = cross_val_predict(rfc, XDim, Y,cv=10)\n",
    "print(accuracy_score(Y,YPred))\n",
    "print(confusion_matrix(Y,YPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on Test Set\n",
    "The final results of the model after being run on the test set are very similar to the training's cross validation predictions. With an Accuracy of .999 and a f-score of .999. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02376529853026663\n",
      "Accuracy: 0.9994352105857673\n",
      "[[4481    2]\n",
      " [   5 7906]]\n",
      "0.9995574941526013\n"
     ]
    }
   ],
   "source": [
    "final_pred = rfc.predict(XTestDim)\n",
    "final_mse = mean_squared_error(YTest,final_pred)\n",
    "print(np.sqrt(final_mse))\n",
    "print (\"Accuracy: %s\" % (accuracy_score(YTest, final_pred)))\n",
    "print(confusion_matrix(YTest,final_pred))\n",
    "print(f1_score(YTest,final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Findings\n",
    "What this means is that a machine can almost perfectly predict whither or not someone is stressed or amused. However, this does not predict other emotions. \n",
    "So the significant findings of the machine learning part of the project are that there is a significant difference in body conditions between stress and amusement. Does this result mean a machine can accurately predict somones emotions? Probably not. This model is really only good if we know someone is stressed or amused, just not which one. \n",
    "While it isn't an amazing finding, it does start as a stepping stone into machines reading emotions, and how differently our bodies react to different stimuli.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
